{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 4.1] Deploy Built-in TFS Image\n",
    "\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‘ì—…ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ëª¨ë¸ ì•„í‹°í™íŠ¸ (model.tar.gz) íŒŒì¼ì„ S3ì—ì„œ ë¡œì»¬ì— ë‹¤ìš´ë¡œë“œ\n",
    "- TF Saved_Model ì˜ ì •ì˜ë¥¼ í™•ì¸\n",
    "- SageMaker Model ìƒì„±\n",
    "- Endpoint ìƒì„±\n",
    "- Inferenceì˜ Request Serializer and Deserializer ìƒì„±\n",
    "- í”„ë¦¬ë”•í„° ìƒì„±\n",
    "- ì…ˆí”Œ ë°ì´íƒ€ë¡œ ì¶”ë¡ \n",
    "\n",
    "---\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ì•½ 10ë¶„ ì •ë„ ì†Œìš” ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•„ìš”í•œ í”„ë¡œê·¸ë¨ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "astroid 2.3.3 requires wrapt==1.11.*, but you'll have wrapt 1.12.1 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade pip\n",
    "!pip install -q wrapt --upgrade --ignore-installed\n",
    "!pip install -q tensorflow==2.1.0\n",
    "!pip install -q transformers==2.8.0\n",
    "!pip install -q sagemaker==1.56.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-training-2020-08-17-09-58-09-919\n"
     ]
    }
   ],
   "source": [
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ì •ì˜ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•„ë˜ì˜ ì„¸ê°œì˜ ì…€ì€ ëª¨ë¸ì„ ë¡œì»¬ì— ë‹¤ìš´ë¡œë“œ ë°›ê³  í…ì„œí”Œë¡œìš°ì˜ Saved Modelì˜ ì •ì˜ (ì…ë ¥, ì¶œë ¥)ë¥¼ í™•ì¸í•˜ëŠ” ì½”ë“œ ì…ë‹ˆë‹¤. í™•ì¸ì„ ì›í•˜ì‹œë©´ ì•„ë˜ ì£¼ì„ì„ ì œê±°í•˜ê³  ì‹¤í–‰í•˜ì‹œë©´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_download = 'model'\n",
    "# os.makedirs(model_download, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 cp s3://$bucket/$training_job_name/output/model.tar.gz {model_download}/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xvzf   {model_download}/model.tar.gz\n",
    "# !saved_model_cli show --all --dir ./tensorflow/saved_model/0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Model ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model = Model(model_data='s3://{}/{}/output/model.tar.gz'.format(bucket, training_job_name),\n",
    "              role=role,\n",
    "              framework_version='2.0.0') # Elastic Inference does not yet support TF 2.1.0 as of sagemaker==1.56.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "instance_type='ml.m4.xlarge'\n",
    "\n",
    "deployed_model = model.deploy(initial_instance_count = 1,\n",
    "                             instance_type = instance_type,\n",
    "                             wait=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name:  tensorflow-inference-2020-08-17-10-16-41-783\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = deployed_model.endpoint\n",
    "print('Endpoint name:  {}'.format(endpoint_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Request Serializer and Deserializer ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestHandler(object):\n",
    "    import json\n",
    "    \n",
    "    def __init__(self, tokenizer, max_seq_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __call__(self, instances):\n",
    "        transformed_instances = []\n",
    "\n",
    "        for instance in instances:\n",
    "            encode_plus_tokens = tokenizer.encode_plus(instance,\n",
    "                                                       pad_to_max_length=True,\n",
    "                                                       max_length=self.max_seq_length)\n",
    "\n",
    "            input_ids = encode_plus_tokens['input_ids']\n",
    "            input_mask = encode_plus_tokens['attention_mask']\n",
    "            segment_ids = [0] * self.max_seq_length\n",
    "\n",
    "            transformed_instance = {\"input_ids\": input_ids, \n",
    "                                    \"input_mask\": input_mask, \n",
    "                                    \"segment_ids\": segment_ids}\n",
    "\n",
    "            transformed_instances.append(transformed_instance)\n",
    "\n",
    "        transformed_data = {\"instances\": transformed_instances}\n",
    "\n",
    "        return json.dumps(transformed_data)\n",
    "    \n",
    "class ResponseHandler(object):\n",
    "    import json\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "    \n",
    "    def __call__(self, response, accept_header):\n",
    "        import tensorflow as tf\n",
    "\n",
    "        response_body = response.read().decode('utf-8')\n",
    "\n",
    "        response_json = json.loads(response_body)\n",
    "\n",
    "        log_probabilities = response_json[\"predictions\"]\n",
    "\n",
    "#        predicted_classes = []\n",
    "\n",
    "        # Convert log_probabilities => softmax (all probabilities add up to 1) => argmax (final prediction)\n",
    "#         for log_probability in log_probabilities:\n",
    "#             softmax = tf.nn.softmax(log_probability)    \n",
    "#             predicted_class_idx = tf.argmax(softmax, axis=-1, output_type=tf.int32)\n",
    "#             predicted_class = self.classes[predicted_class_idx]\n",
    "#             predicted_classes.append(predicted_class)\n",
    "\n",
    "        return log_probabilities    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.tensorflow.serving import Predictor\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "request_handler = RequestHandler(tokenizer=tokenizer,\n",
    "                                 max_seq_length=32)\n",
    "\n",
    "response_handler = ResponseHandler(classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "predictor = Predictor(endpoint_name=endpoint_name,\n",
    "                      sagemaker_session=sess,\n",
    "                      serializer=request_handler,\n",
    "                      deserializer=response_handler,\n",
    "                      content_type='application/json',\n",
    "                      model_name='saved_model',\n",
    "                      model_version=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji_to_idx is loaded\n",
      "ğŸ˜‚\n"
     ]
    }
   ],
   "source": [
    "from TweetUtil import TweetUtil\n",
    "\n",
    "tweet_util = TweetUtil()\n",
    "tweet_util.load_emoji_data('emoji_to_idx.pickle')\n",
    "emoji = tweet_util.get_emo_class_label(3)\n",
    "print(emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>yesterday the air conditioner was on in the bu...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5954</th>\n",
       "      <td>loving these colors</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7638</th>\n",
       "      <td>thank you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>vapemail thanks dude can't wait to open them ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9033</th>\n",
       "      <td>niggas really forget who was down when nobody...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>okay i followed you so try again please</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4330</th>\n",
       "      <td>bless up</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7147</th>\n",
       "      <td>that deep sleepy voice</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>i've noticed that social media is the cause to...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>i always turn it off here i love the s6 finale</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TWEET  LABEL\n",
       "2323  yesterday the air conditioner was on in the bu...      8\n",
       "5954                                loving these colors      5\n",
       "7638                                         thank you       0\n",
       "2743   vapemail thanks dude can't wait to open them ...      4\n",
       "9033   niggas really forget who was down when nobody...      7\n",
       "432             okay i followed you so try again please      4\n",
       "4330                                           bless up      5\n",
       "7147                             that deep sleepy voice      3\n",
       "3885  i've noticed that social media is the cause to...      9\n",
       "150      i always turn it off here i love the s6 finale      5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_path = 'data/test/tweet_file_test.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "test_file_path = 'data/test/tweet_file_test.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "sample_df = test_df.sample(10)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_N_label(score_list, topN):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    top_n_idx = np.argsort(score_list)[-topN:]\n",
    "    top_n_values = [score_list[i] for i in top_n_idx]\n",
    "    \n",
    "    top_n_idx_list = top_n_idx.tolist()\n",
    "    top_n_idx_list.reverse()\n",
    "    top_n_values = [score_list[i] for i in top_n_idx_list]    \n",
    "    \n",
    "    return top_n_idx_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet: as if flynn said jill you don't know what it's like being 12 can you even remember being 12 mate i'm 18 not 80 \n",
      "Ground_truth- 8:ğŸ™„\n",
      " \n",
      "Prediction: 3,ğŸ˜‚,7,ğŸ˜­,9,ğŸ¤”,8,ğŸ™„,4,ğŸ˜Š \n",
      " \n",
      "tweet: so 80 hr to cuddle with strangers welp might have to work my way into the cuddling industry  \n",
      "Ground_truth- 9:ğŸ¤”\n",
      " \n",
      "Prediction: 8,ğŸ™„,7,ğŸ˜­,3,ğŸ˜‚,9,ğŸ¤”,4,ğŸ˜Š \n",
      " \n",
      "tweet:  car freestyle session \n",
      "Ground_truth- 2:ğŸ”¥\n",
      " \n",
      "Prediction: 6,ğŸ˜©,2,ğŸ”¥,4,ğŸ˜Š,8,ğŸ™„,1,ğŸ’• \n",
      " \n",
      "tweet:  how can people be jealous of a innocent lil baby like wtf especially if she he not even here yet just sad son  \n",
      "Ground_truth- 9:ğŸ¤”\n",
      " \n",
      "Prediction: 8,ğŸ™„,3,ğŸ˜‚,4,ğŸ˜Š,5,ğŸ˜,0,â¤ \n",
      " \n",
      "tweet: got punched last night just because i was standing in the the wrong place at the wrong time \n",
      "Ground_truth- 3:ğŸ˜‚\n",
      " \n",
      "Prediction: 8,ğŸ™„,9,ğŸ¤”,6,ğŸ˜©,2,ğŸ”¥,7,ğŸ˜­ \n",
      " \n",
      "tweet: finally off \n",
      "Ground_truth- 8:ğŸ™„\n",
      " \n",
      "Prediction: 3,ğŸ˜‚,8,ğŸ™„,4,ğŸ˜Š,7,ğŸ˜­,5,ğŸ˜ \n",
      " \n",
      "tweet:  all the time \n",
      "Ground_truth- 7:ğŸ˜­\n",
      " \n",
      "Prediction: 4,ğŸ˜Š,8,ğŸ™„,2,ğŸ”¥,7,ğŸ˜­,0,â¤ \n",
      " \n",
      "tweet:  i don't know if y'all ready \n",
      "Ground_truth- 2:ğŸ”¥\n",
      " \n",
      "Prediction: 3,ğŸ˜‚,9,ğŸ¤”,5,ğŸ˜,8,ğŸ™„,4,ğŸ˜Š \n",
      " \n",
      "tweet:  same with pornhub vote rank and subscribe please and thank you  \n",
      "Ground_truth- 4:ğŸ˜Š\n",
      " \n",
      "Prediction: 4,ğŸ˜Š,0,â¤,1,ğŸ’•,2,ğŸ”¥,8,ğŸ™„ \n",
      " \n",
      "tweet:  check our pinned tweet to enter in our giveaway  \n",
      "Ground_truth- 2:ğŸ”¥\n",
      " \n",
      "Prediction: 1,ğŸ’•,4,ğŸ˜Š,2,ğŸ”¥,8,ğŸ™„,0,â¤ \n",
      " \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "columns = ['TWEET', 'LABEL']\n",
    "topN = 5\n",
    "for tweet, label in zip(sample_df.TWEET.values, sample_df.LABEL.values):\n",
    "    # print(\"label: {}, tweet: {}\".format(label, tweet))\n",
    "    \n",
    "    reviews = [tweet]\n",
    "    \n",
    "#     print(\"reviews: \\n\", reviews)\n",
    "\n",
    "\n",
    "\n",
    "    predicted_classes = predictor.predict(reviews)[0]\n",
    "#    predicted_classes = predictor.predict(reviews)    \n",
    "    predicted_classes = show_top_N_label(predicted_classes, topN)\n",
    "\n",
    "    print('tweet: {} \\nGround_truth- {}:{}\\n '.format(\n",
    "        tweet,\n",
    "        label, \n",
    "        tweet_util.get_emo_class_label(label))\n",
    "         )    \n",
    "    \n",
    "\n",
    "    print('Prediction: {},{},{},{},{},{},{},{},{},{} \\n '.format(\n",
    "        predicted_classes[0], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[0]),\n",
    "        predicted_classes[1], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[1]),\n",
    "        predicted_classes[2], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[2]),                                       \n",
    "        predicted_classes[3], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[3]),                                      \n",
    "        predicted_classes[4], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[4]),                                      \n",
    "        \n",
    "        ))    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
