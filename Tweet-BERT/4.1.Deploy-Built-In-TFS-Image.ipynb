{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 4.1] Deploy Built-in TFS Image\n",
    "\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‘ì—…ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ëª¨ë¸ ì•„í‹°í™íŠ¸ (model.tar.gz) íŒŒì¼ì„ S3ì—ì„œ ë¡œì»¬ì— ë‹¤ìš´ë¡œë“œ\n",
    "- TF Saved_Model ì˜ ì •ì˜ë¥¼ í™•ì¸\n",
    "- SageMaker Model ìƒì„±\n",
    "- Endpoint ìƒì„±\n",
    "- Inferenceì˜ Request Serializer and Deserializer ìƒì„±\n",
    "- í”„ë¦¬ë”•í„° ìƒì„±\n",
    "- ì…ˆí”Œ ë°ì´íƒ€ë¡œ ì¶”ë¡ \n",
    "\n",
    "---\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ì•½ 10ë¶„ ì •ë„ ì†Œìš” ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•„ìš”í•œ í”„ë¡œê·¸ë¨ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "astroid 2.3.3 requires wrapt==1.11.*, but you'll have wrapt 1.12.1 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade pip\n",
    "!pip install -q wrapt --upgrade --ignore-installed\n",
    "!pip install -q tensorflow==2.1.0\n",
    "!pip install -q transformers==2.8.0\n",
    "!pip install -q sagemaker==1.56.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert2tweet-2020-08-19-05-23-18-129\n"
     ]
    }
   ],
   "source": [
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ì •ì˜ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•„ë˜ì˜ ì„¸ê°œì˜ ì…€ì€ ëª¨ë¸ì„ ë¡œì»¬ì— ë‹¤ìš´ë¡œë“œ ë°›ê³  í…ì„œí”Œë¡œìš°ì˜ Saved Modelì˜ ì •ì˜ (ì…ë ¥, ì¶œë ¥)ë¥¼ í™•ì¸í•˜ëŠ” ì½”ë“œ ì…ë‹ˆë‹¤. í™•ì¸ì„ ì›í•˜ì‹œë©´ ì•„ë˜ ì£¼ì„ì„ ì œê±°í•˜ê³  ì‹¤í–‰í•˜ì‹œë©´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_download = 'model'\n",
    "# os.makedirs(model_download, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 cp s3://$bucket/$training_job_name/output/model.tar.gz {model_download}/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xvzf   {model_download}/model.tar.gz\n",
    "# !saved_model_cli show --all --dir ./tensorflow/saved_model/0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Model ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model = Model(model_data='s3://{}/{}/output/model.tar.gz'.format(bucket, training_job_name),\n",
    "              role=role,\n",
    "              framework_version='2.0.0') # Elastic Inference does not yet support TF 2.1.0 as of sagemaker==1.56.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "instance_type='ml.m4.xlarge'\n",
    "\n",
    "import time\n",
    "endpont_name    = f'builtin-inference-image-endpoint-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())}'\n",
    "\n",
    "\n",
    "\n",
    "deployed_model = model.deploy(\n",
    "                             endpoint_name = endpont_name,\n",
    "                             initial_instance_count = 1,\n",
    "                             instance_type = instance_type,\n",
    "                             wait=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name:  builtin-inference-image-endpoint-2020-08-19-05-54-43\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = deployed_model.endpoint\n",
    "print('Endpoint name:  {}'.format(endpoint_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Request Serializer and Deserializer ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestHandler(object):\n",
    "    import json\n",
    "    \n",
    "    def __init__(self, tokenizer, max_seq_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __call__(self, instances):\n",
    "        transformed_instances = []\n",
    "\n",
    "        for instance in instances:\n",
    "            encode_plus_tokens = tokenizer.encode_plus(instance,\n",
    "                                                       pad_to_max_length=True,\n",
    "                                                       max_length=self.max_seq_length)\n",
    "\n",
    "            input_ids = encode_plus_tokens['input_ids']\n",
    "            input_mask = encode_plus_tokens['attention_mask']\n",
    "            segment_ids = [0] * self.max_seq_length\n",
    "\n",
    "            transformed_instance = {\"input_ids\": input_ids, \n",
    "                                    \"input_mask\": input_mask, \n",
    "                                    \"segment_ids\": segment_ids}\n",
    "\n",
    "            transformed_instances.append(transformed_instance)\n",
    "\n",
    "        transformed_data = {\"instances\": transformed_instances}\n",
    "\n",
    "        return json.dumps(transformed_data)\n",
    "    \n",
    "class ResponseHandler(object):\n",
    "    import json\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "    \n",
    "    def __call__(self, response, accept_header):\n",
    "        import tensorflow as tf\n",
    "\n",
    "        response_body = response.read().decode('utf-8')\n",
    "\n",
    "        response_json = json.loads(response_body)\n",
    "\n",
    "        log_probabilities = response_json[\"predictions\"]\n",
    "\n",
    "#        predicted_classes = []\n",
    "\n",
    "        # Convert log_probabilities => softmax (all probabilities add up to 1) => argmax (final prediction)\n",
    "#         for log_probability in log_probabilities:\n",
    "#             softmax = tf.nn.softmax(log_probability)    \n",
    "#             predicted_class_idx = tf.argmax(softmax, axis=-1, output_type=tf.int32)\n",
    "#             predicted_class = self.classes[predicted_class_idx]\n",
    "#             predicted_classes.append(predicted_class)\n",
    "\n",
    "        return log_probabilities    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.tensorflow.serving import Predictor\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "request_handler = RequestHandler(tokenizer=tokenizer,\n",
    "                                 max_seq_length=32)\n",
    "\n",
    "response_handler = ResponseHandler(classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "predictor = Predictor(endpoint_name=endpoint_name,\n",
    "                      sagemaker_session=sess,\n",
    "                      serializer=request_handler,\n",
    "                      deserializer=response_handler,\n",
    "                      content_type='application/json',\n",
    "                      model_name='saved_model',\n",
    "                      model_version=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji_to_idx is loaded\n",
      "ğŸ˜‚\n"
     ]
    }
   ],
   "source": [
    "from TweetUtil import TweetUtil\n",
    "\n",
    "tweet_util = TweetUtil()\n",
    "tweet_util.load_emoji_data('emoji_to_idx.pickle')\n",
    "emoji = tweet_util.get_emo_class_label(3)\n",
    "print(emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>lawa siot wendy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>finished all 5 haunted houses in 2 hours</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>daddy</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>you guys will also perform these steps</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>check out me new video cut retweet comment 1u...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>rare moment between mannu salahuddin sannu ma...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5372</th>\n",
       "      <td>holy wow</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>s'talk loan agreements</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>how cute is evelyne holding cosima's funko pop</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>definitely</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TWEET  LABEL\n",
       "2074                                    lawa siot wendy      5\n",
       "1001          finished all 5 haunted houses in 2 hours       1\n",
       "3950                                              daddy      7\n",
       "1882            you guys will also perform these steps       5\n",
       "5257   check out me new video cut retweet comment 1u...      2\n",
       "1400   rare moment between mannu salahuddin sannu ma...      5\n",
       "5372                                           holy wow      5\n",
       "7487                             s'talk loan agreements      9\n",
       "6391     how cute is evelyne holding cosima's funko pop      5\n",
       "3978                                        definitely       2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_path = 'data/test/tweet_file_test.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "test_file_path = 'data/test/tweet_file_test.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "sample_df = test_df.sample(10)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_N_label(score_list, topN):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    top_n_idx = np.argsort(score_list)[-topN:]\n",
    "    top_n_values = [score_list[i] for i in top_n_idx]\n",
    "    \n",
    "    top_n_idx_list = top_n_idx.tolist()\n",
    "    top_n_idx_list.reverse()\n",
    "    top_n_values = [score_list[i] for i in top_n_idx_list]    \n",
    "    \n",
    "    return top_n_idx_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "tweet: lawa siot wendy \n",
      "Ground_truth- 5:ğŸ˜\n",
      " \n",
      "Prediction: 3,ğŸ˜‚,5,ğŸ˜,2,ğŸ”¥,1,ğŸ’•,7,ğŸ˜­ \n",
      " \n",
      "-------------------------------------------\n",
      "tweet:  finished all 5 haunted houses in 2 hours  \n",
      "Ground_truth- 1:ğŸ’•\n",
      " \n",
      "Prediction: 5,ğŸ˜,2,ğŸ”¥,8,ğŸ™„,4,ğŸ˜Š,6,ğŸ˜© \n",
      " \n",
      "-------------------------------------------\n",
      "tweet:  daddy \n",
      "Ground_truth- 7:ğŸ˜­\n",
      " \n",
      "Prediction: 5,ğŸ˜,1,ğŸ’•,3,ğŸ˜‚,7,ğŸ˜­,4,ğŸ˜Š \n",
      " \n",
      "-------------------------------------------\n",
      "tweet:  you guys will also perform these steps  \n",
      "Ground_truth- 5:ğŸ˜\n",
      " \n",
      "Prediction: 2,ğŸ”¥,1,ğŸ’•,3,ğŸ˜‚,5,ğŸ˜,4,ğŸ˜Š \n",
      " \n",
      "-------------------------------------------\n",
      "tweet:  check out me new video cut retweet comment 1up westoakland realrichmond \n",
      "Ground_truth- 2:ğŸ”¥\n",
      " \n",
      "Prediction: 2,ğŸ”¥,4,ğŸ˜Š,1,ğŸ’•,0,â¤,5,ğŸ˜ \n",
      " \n",
      "-------------------------------------------\n",
      "tweet:  rare moment between mannu salahuddin sannu mannu mannmayal 5daystogo lastepisode humtv mayaali https t  \n",
      "Ground_truth- 5:ğŸ˜\n",
      " \n",
      "Prediction: 5,ğŸ˜,3,ğŸ˜‚,0,â¤,4,ğŸ˜Š,7,ğŸ˜­ \n",
      " \n",
      "-------------------------------------------\n",
      "tweet:  holy wow \n",
      "Ground_truth- 5:ğŸ˜\n",
      " \n",
      "Prediction: 5,ğŸ˜,4,ğŸ˜Š,2,ğŸ”¥,3,ğŸ˜‚,1,ğŸ’• \n",
      " \n",
      "-------------------------------------------\n",
      "tweet: s'talk loan agreements \n",
      "Ground_truth- 9:ğŸ¤”\n",
      " \n",
      "Prediction: 4,ğŸ˜Š,0,â¤,6,ğŸ˜©,3,ğŸ˜‚,2,ğŸ”¥ \n",
      " \n",
      "-------------------------------------------\n",
      "tweet: how cute is evelyne holding cosima's funko pop \n",
      "Ground_truth- 5:ğŸ˜\n",
      " \n",
      "Prediction: 5,ğŸ˜,1,ğŸ’•,7,ğŸ˜­,0,â¤,2,ğŸ”¥ \n",
      " \n",
      "-------------------------------------------\n",
      "tweet:  definitely  \n",
      "Ground_truth- 2:ğŸ”¥\n",
      " \n",
      "Prediction: 3,ğŸ˜‚,4,ğŸ˜Š,8,ğŸ™„,5,ğŸ˜,7,ğŸ˜­ \n",
      " \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "columns = ['TWEET', 'LABEL']\n",
    "topN = 5\n",
    "for tweet, label in zip(sample_df.TWEET.values, sample_df.LABEL.values):\n",
    "    # print(\"label: {}, tweet: {}\".format(label, tweet))\n",
    "    \n",
    "    reviews = [tweet]\n",
    "    \n",
    "#     print(\"reviews: \\n\", reviews)\n",
    "\n",
    "\n",
    "\n",
    "    predicted_classes = predictor.predict(reviews)[0]\n",
    "#    predicted_classes = predictor.predict(reviews)    \n",
    "    predicted_classes = show_top_N_label(predicted_classes, topN)\n",
    "\n",
    "    print('-------------------------------------------')    \n",
    "    print('tweet: {} \\nGround_truth- {}:{}\\n '.format(\n",
    "        tweet,\n",
    "        label, \n",
    "        tweet_util.get_emo_class_label(label))\n",
    "         )    \n",
    "    \n",
    "\n",
    "    print('Prediction: {},{},{},{},{},{},{},{},{},{} \\n '.format(\n",
    "        predicted_classes[0], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[0]),\n",
    "        predicted_classes[1], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[1]),\n",
    "        predicted_classes[2], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[2]),                                       \n",
    "        predicted_classes[3], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[3]),                                      \n",
    "        predicted_classes[4], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[4]),                                      \n",
    "        \n",
    "        ))    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
