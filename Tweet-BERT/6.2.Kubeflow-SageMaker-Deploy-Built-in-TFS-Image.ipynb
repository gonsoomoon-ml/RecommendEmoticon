{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 6.2] Kubeflow에서 요청하여 만든 SageMaker 모델 기반으로 추론 \n",
    "\n",
    "이 노트북은 Kubeflow Pipeline에서 SageMaker로 Training job을 요청을 했고, <br>\n",
    "생성한 모델 아티펙트를 가져와서 추론을 합니다.\n",
    "\n",
    "\n",
    "**아래 일부 코드는 하드코드가 되어 있습니다. \n",
    "(예: training job, inference image 등) \n",
    "실제 환경 구성후에 실행시 변경 해야 합니다.**\n",
    "\n",
    "---\n",
    "이 노트북은 약 10분 정도 시간이 소요 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Train Model Invoked by KubeFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "엔드포인트를 만들기 위해 아래 두가지를 준비 합니다.\n",
    "- SageMaker Training Job을 가져와서 Model Artifact를 사용 합니다.\n",
    "- \"4.2.1.Make-Custom-Inference-Image-ECR.ipynb\" 에서 생성하여 ECR에 등록한 추론 이미지를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker train job from KubeFlow: \n",
      " s3://sagemaker-ap-northeast-2-790639055451/bert-kf-output/TrainingJob-20210408140238-J5UG/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# model_data = 's3://sagemaker-ap-northeast-2-790639055451/bert-kf-output/TrainingJob-20210408140238-J5UG/output/model.tar.gz'\n",
    "model_data = '<>'\n",
    "print('sagemaker train job from KubeFlow: \\n', model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference_image:  343441690612.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving:2.0.0-cpu\n"
     ]
    }
   ],
   "source": [
    "# inference_image = '790639055451.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving:2.0-cpu'\n",
    "inference_image = <>\n",
    "print(\"inference_image: \", inference_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 엔드포인트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!CPU times: user 1min 4s, sys: 10.8 s, total: 1min 15s\n",
      "Wall time: 7min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "import time\n",
    "endpont_name    = f'kubeflow-custom-inference-image-endpoint-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())}'\n",
    "\n",
    "\n",
    "\n",
    "model = Model(model_data= model_data,\n",
    "              role=role,\n",
    "              entry_point='inference.py',\n",
    "              image = inference_image\n",
    "             ) \n",
    "\n",
    "instance_type='ml.m4.xlarge'\n",
    "deployed_model = model.deploy(\n",
    "                             endpoint_name= endpont_name,\n",
    "                             initial_instance_count = 1,\n",
    "                             instance_type = instance_type,\n",
    "                             wait=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor Creation on the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubeflow-custom-inference-image-endpoint-2020-08-19-05-54-51\n"
     ]
    }
   ],
   "source": [
    "# tweet_bert_endpoint_name = 'train_text, train_label, test_text, test_label = tweet_data.split_train_test_data(texts, labels, 0.9)\n",
    "tweet_bert_endpoint_name = deployed_model.endpoint\n",
    "print(tweet_bert_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.tensorflow.serving import Predictor\n",
    "\n",
    "predictor = Predictor(endpoint_name = tweet_bert_endpoint_name,\n",
    "                      sagemaker_session = sess,\n",
    "                      content_type = 'application/json',\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji_to_idx is loaded\n",
      "😂\n"
     ]
    }
   ],
   "source": [
    "from TweetUtil import TweetUtil\n",
    "\n",
    "tweet_util = TweetUtil()\n",
    "tweet_util.load_emoji_data('emoji_to_idx.pickle')\n",
    "emoji = tweet_util.get_emo_class_label(3)\n",
    "print(emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>a6 we this pic of perth but which scottish ci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>lisa rap better than dahyun but still love to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>we a hawt squad</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8070</th>\n",
       "      <td>this is just beautiful</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>thank you so much team live for supporting ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>me you know taken him what's that me you've n...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8534</th>\n",
       "      <td>thanks ruby u the homie let's get it done this...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>i don't feel like going to work</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>lose you already did quit frontin</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8005</th>\n",
       "      <td>girl</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TWEET  LABEL\n",
       "2491   a6 we this pic of perth but which scottish ci...      0\n",
       "2557  lisa rap better than dahyun but still love to ...      1\n",
       "4604                                    we a hawt squad      2\n",
       "8070                             this is just beautiful      6\n",
       "4049   thank you so much team live for supporting ou...      0\n",
       "1194   me you know taken him what's that me you've n...      9\n",
       "8534  thanks ruby u the homie let's get it done this...      2\n",
       "2058                    i don't feel like going to work      8\n",
       "1139                  lose you already did quit frontin      3\n",
       "8005                                              girl       2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_path = 'data/test/tweet_file_test.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "test_file_path = 'data/test/tweet_file_test.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "sample_df = test_df.sample(10)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_N_label(score_list, topN):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    top_n_idx = np.argsort(score_list)[-topN:]\n",
    "    top_n_values = [score_list[i] for i in top_n_idx]\n",
    "    \n",
    "    top_n_idx_list = top_n_idx.tolist()\n",
    "    top_n_idx_list.reverse()\n",
    "    top_n_values = [score_list[i] for i in top_n_idx_list]    \n",
    "    \n",
    "    return top_n_idx_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 이모티콘 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "tweet:  a6 we this pic of perth but which scottish city will you vote for scotlandhour perthuk htt \n",
      "Ground_truth- 0:❤\n",
      " \n",
      "Prediction: 7,😭,9,🤔,1,💕,3,😂,4,😊 \n",
      " \n",
      "-------------------------------------------\n",
      "tweet: lisa rap better than dahyun but still love to hear dahyun cute voice \n",
      "Ground_truth- 1:💕\n",
      " \n",
      "Prediction: 5,😍,0,❤,3,😂,2,🔥,1,💕 \n",
      " \n",
      "-------------------------------------------\n",
      "tweet:  we a hawt squad \n",
      "Ground_truth- 2:🔥\n",
      " \n",
      "Prediction: 4,😊,7,😭,1,💕,5,😍,0,❤ \n",
      " \n",
      "-------------------------------------------\n",
      "tweet:  this is just beautiful \n",
      "Ground_truth- 6:😩\n",
      " \n",
      "Prediction: 6,😩,3,😂,5,😍,1,💕,4,😊 \n",
      " \n",
      "-------------------------------------------\n",
      "tweet:  thank you so much team live for supporting our queen \n",
      "Ground_truth- 0:❤\n",
      " \n",
      "Prediction: 1,💕,4,😊,0,❤,5,😍,7,😭 \n",
      " \n",
      "-------------------------------------------\n",
      "tweet:  me you know taken him what's that me you've never seen taken  \n",
      "Ground_truth- 9:🤔\n",
      " \n",
      "Prediction: 9,🤔,3,😂,8,🙄,7,😭,6,😩 \n",
      " \n",
      "-------------------------------------------\n",
      "tweet: thanks ruby u the homie let's get it done this weekend about to be lit \n",
      "Ground_truth- 2:🔥\n",
      " \n",
      "Prediction: 2,🔥,4,😊,5,😍,0,❤,1,💕 \n",
      " \n",
      "-------------------------------------------\n",
      "tweet: i don't feel like going to work \n",
      "Ground_truth- 8:🙄\n",
      " \n",
      "Prediction: 8,🙄,6,😩,9,🤔,4,😊,7,😭 \n",
      " \n",
      "-------------------------------------------\n",
      "tweet:  lose you already did quit frontin \n",
      "Ground_truth- 3:😂\n",
      " \n",
      "Prediction: 4,😊,7,😭,5,😍,2,🔥,6,😩 \n",
      " \n",
      "-------------------------------------------\n",
      "tweet:  girl  \n",
      "Ground_truth- 2:🔥\n",
      " \n",
      "Prediction: 6,😩,1,💕,4,😊,7,😭,9,🤔 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "columns = ['TWEET', 'LABEL']\n",
    "topN = 5\n",
    "for tweet, label in zip(sample_df.TWEET.values, sample_df.LABEL.values):\n",
    "    tweets = [tweet]    \n",
    "    predicted_classes = predictor.predict(tweets)[0]\n",
    "    predicted_classes = show_top_N_label(predicted_classes, topN)\n",
    "\n",
    "    print('-------------------------------------------')        \n",
    "    print('tweet: {} \\nGround_truth- {}:{}\\n '.format(\n",
    "        tweet,\n",
    "        label, \n",
    "        tweet_util.get_emo_class_label(label))\n",
    "         )    \n",
    "    print('Prediction: {},{},{},{},{},{},{},{},{},{} \\n '.format(\n",
    "        predicted_classes[0], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[0]),\n",
    "        predicted_classes[1], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[1]),\n",
    "        predicted_classes[2], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[2]),   \n",
    "        predicted_classes[3], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[3]),                                      \n",
    "        predicted_classes[4], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[4]),                                      \n",
    "        ))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
