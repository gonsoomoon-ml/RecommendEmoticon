{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 4.1] Deploy from Scratch\n",
    "\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‘ì—…ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ëª¨ë¸ ì•„í‹°í™íŠ¸ (model.tar.gz) íŒŒì¼ì„ S3ì—ì„œ ë¡œì»¬ì— ë‹¤ìš´ë¡œë“œ\n",
    "- TF Saved_Model ì˜ ì •ì˜ë¥¼ í™•ì¸\n",
    "- SageMaker Model ìƒì„±\n",
    "- Endpoint ìƒì„±\n",
    "- Inferenceì˜ Request Serializer and Deserializer ìƒì„±\n",
    "- í”„ë¦¬ë”•í„° ìƒì„±\n",
    "- ì…ˆí”Œ ë°ì´íƒ€ë¡œ ì¶”ë¡ \n",
    "\n",
    "---\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ì•½ 10ë¶„ ì •ë„ ì†Œìš” ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•„ìš”í•œ í”„ë¡œê·¸ë¨ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "astroid 2.3.3 requires wrapt==1.11.*, but you'll have wrapt 1.12.1 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --upgrade pip\n",
    "!pip install -q wrapt --upgrade --ignore-installed\n",
    "!pip install -q tensorflow==2.1.0\n",
    "!pip install -q transformers==2.8.0\n",
    "!pip install -q sagemaker==1.56.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Model to the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-training-2020-08-02-12-18-28-858\n"
     ]
    }
   ],
   "source": [
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_download = 'model'\n",
    "os.makedirs(model_download, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-northeast-2-343441690612/tensorflow-training-2020-08-02-12-18-28-858/output/model.tar.gz to model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://$bucket/$training_job_name/output/model.tar.gz {model_download}/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xvzf   {model_download}/model.tar.gz\n",
    "# !saved_model_cli show --all --dir ./tensorflow/saved_model/0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Model ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model = Model(model_data='s3://{}/{}/output/model.tar.gz'.format(bucket, training_job_name),\n",
    "              role=role,\n",
    "              framework_version='2.0.0') # Elastic Inference does not yet support TF 2.1.0 as of sagemaker==1.56.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "instance_type='ml.m4.xlarge'\n",
    "\n",
    "deployed_model = model.deploy(initial_instance_count = 1,\n",
    "                             instance_type = instance_type,\n",
    "                             wait=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name:  tensorflow-inference-2020-08-02-12-37-40-784\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = deployed_model.endpoint\n",
    "print('Endpoint name:  {}'.format(endpoint_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Request Serializer and Deserializer ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestHandler(object):\n",
    "    import json\n",
    "    \n",
    "    def __init__(self, tokenizer, max_seq_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __call__(self, instances):\n",
    "        transformed_instances = []\n",
    "\n",
    "        for instance in instances:\n",
    "            encode_plus_tokens = tokenizer.encode_plus(instance,\n",
    "                                                       pad_to_max_length=True,\n",
    "                                                       max_length=self.max_seq_length)\n",
    "\n",
    "            input_ids = encode_plus_tokens['input_ids']\n",
    "            input_mask = encode_plus_tokens['attention_mask']\n",
    "            segment_ids = [0] * self.max_seq_length\n",
    "\n",
    "            transformed_instance = {\"input_ids\": input_ids, \n",
    "                                    \"input_mask\": input_mask, \n",
    "                                    \"segment_ids\": segment_ids}\n",
    "\n",
    "            transformed_instances.append(transformed_instance)\n",
    "\n",
    "        transformed_data = {\"instances\": transformed_instances}\n",
    "\n",
    "        return json.dumps(transformed_data)\n",
    "    \n",
    "class ResponseHandler(object):\n",
    "    import json\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "    \n",
    "    def __call__(self, response, accept_header):\n",
    "        import tensorflow as tf\n",
    "\n",
    "        response_body = response.read().decode('utf-8')\n",
    "\n",
    "        response_json = json.loads(response_body)\n",
    "\n",
    "        log_probabilities = response_json[\"predictions\"]\n",
    "\n",
    "#        predicted_classes = []\n",
    "\n",
    "        # Convert log_probabilities => softmax (all probabilities add up to 1) => argmax (final prediction)\n",
    "#         for log_probability in log_probabilities:\n",
    "#             softmax = tf.nn.softmax(log_probability)    \n",
    "#             predicted_class_idx = tf.argmax(softmax, axis=-1, output_type=tf.int32)\n",
    "#             predicted_class = self.classes[predicted_class_idx]\n",
    "#             predicted_classes.append(predicted_class)\n",
    "\n",
    "        return log_probabilities    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.tensorflow.serving import Predictor\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "request_handler = RequestHandler(tokenizer=tokenizer,\n",
    "                                 max_seq_length=32)\n",
    "\n",
    "response_handler = ResponseHandler(classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "predictor = Predictor(endpoint_name=endpoint_name,\n",
    "                      sagemaker_session=sess,\n",
    "                      serializer=request_handler,\n",
    "                      deserializer=response_handler,\n",
    "                      content_type='application/json',\n",
    "                      model_name='saved_model',\n",
    "                      model_version=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji_to_idx is loaded\n",
      "ğŸ˜‚\n"
     ]
    }
   ],
   "source": [
    "from TweetUtil import TweetUtil\n",
    "\n",
    "tweet_util = TweetUtil()\n",
    "tweet_util.load_emoji_data('emoji_to_idx.pickle')\n",
    "emoji = tweet_util.get_emo_class_label(3)\n",
    "print(emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>a likely story</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8370</th>\n",
       "      <td>african space tour</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>raheem sterling's snapchat story</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>they can't hide the heart eyes</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7494</th>\n",
       "      <td>for anything enchanted kingdom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>actor park</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>my grades are not where i want them to be got...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>you are fabulous good morning pipol happy mon...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4622</th>\n",
       "      <td>lmao why</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>new video go watch my favourite parts were th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TWEET  LABEL\n",
       "2260                                    a likely story       9\n",
       "8370                                 african space tour      2\n",
       "7086                  raheem sterling's snapchat story       7\n",
       "2984                    they can't hide the heart eyes       5\n",
       "7494                     for anything enchanted kingdom      0\n",
       "3603                                         actor park      1\n",
       "3170   my grades are not where i want them to be got...      7\n",
       "549    you are fabulous good morning pipol happy mon...      4\n",
       "4622                                           lmao why      6\n",
       "4374   new video go watch my favourite parts were th...      3"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_path = 'data/test/tweet_file_test.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "test_file_path = 'data/test/tweet_file_test.csv'\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "sample_df = test_df.sample(10)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_N_label(score_list, topN):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    top_n_idx = np.argsort(score_list)[-topN:]\n",
    "    top_n_values = [score_list[i] for i in top_n_idx]\n",
    "    \n",
    "    top_n_idx_list = top_n_idx.tolist()\n",
    "    top_n_idx_list.reverse()\n",
    "    top_n_values = [score_list[i] for i in top_n_idx_list]    \n",
    "    \n",
    "    return top_n_idx_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet:  a likely story  \n",
      "Ground_truth- 9:ğŸ¤”\n",
      " \n",
      "Prediction: 6,ğŸ˜©,7,ğŸ˜­,9,ğŸ¤” \n",
      " \n",
      "tweet:  african space tour \n",
      "Ground_truth- 2:ğŸ”¥\n",
      " \n",
      "Prediction: 2,ğŸ”¥,5,ğŸ˜,7,ğŸ˜­ \n",
      " \n",
      "tweet:  raheem sterling's snapchat story  \n",
      "Ground_truth- 7:ğŸ˜­\n",
      " \n",
      "Prediction: 0,â¤,5,ğŸ˜,3,ğŸ˜‚ \n",
      " \n",
      "tweet:  they can't hide the heart eyes  \n",
      "Ground_truth- 5:ğŸ˜\n",
      " \n",
      "Prediction: 9,ğŸ¤”,5,ğŸ˜,7,ğŸ˜­ \n",
      " \n",
      "tweet: for anything enchanted kingdom \n",
      "Ground_truth- 0:â¤\n",
      " \n",
      "Prediction: 4,ğŸ˜Š,6,ğŸ˜©,1,ğŸ’• \n",
      " \n",
      "tweet: actor park \n",
      "Ground_truth- 1:ğŸ’•\n",
      " \n",
      "Prediction: 4,ğŸ˜Š,7,ğŸ˜­,5,ğŸ˜ \n",
      " \n",
      "tweet:  my grades are not where i want them to be got 1 week to get them up \n",
      "Ground_truth- 7:ğŸ˜­\n",
      " \n",
      "Prediction: 9,ğŸ¤”,8,ğŸ™„,3,ğŸ˜‚ \n",
      " \n",
      "tweet:  you are fabulous good morning pipol happy monday aldubikawlang \n",
      "Ground_truth- 4:ğŸ˜Š\n",
      " \n",
      "Prediction: 0,â¤,1,ğŸ’•,4,ğŸ˜Š \n",
      " \n",
      "tweet:  lmao why \n",
      "Ground_truth- 6:ğŸ˜©\n",
      " \n",
      "Prediction: 8,ğŸ™„,9,ğŸ¤”,6,ğŸ˜© \n",
      " \n",
      "tweet:  new video go watch my favourite parts were the approving your costume the best house wars \n",
      "Ground_truth- 3:ğŸ˜‚\n",
      " \n",
      "Prediction: 1,ğŸ’•,5,ğŸ˜,4,ğŸ˜Š \n",
      " \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "columns = ['TWEET', 'LABEL']\n",
    "topN = 3\n",
    "for tweet, label in zip(sample_df.TWEET.values, sample_df.LABEL.values):\n",
    "    # print(\"label: {}, tweet: {}\".format(label, tweet))\n",
    "    \n",
    "    reviews = [tweet]\n",
    "    \n",
    "#     print(\"reviews: \\n\", reviews)\n",
    "\n",
    "\n",
    "\n",
    "    predicted_classes = predictor.predict(reviews)[0]\n",
    "#    predicted_classes = predictor.predict(reviews)    \n",
    "    predicted_classes = show_top_N_label(predicted_classes, topN)\n",
    "\n",
    "    print('tweet: {} \\nGround_truth- {}:{}\\n '.format(\n",
    "        tweet,\n",
    "        label, \n",
    "        tweet_util.get_emo_class_label(label))\n",
    "         )    \n",
    "    \n",
    "\n",
    "    print('Prediction: {},{},{},{},{},{} \\n '.format(\n",
    "        predicted_classes[0], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[0]),\n",
    "        predicted_classes[1], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[1]),\n",
    "        predicted_classes[2], \n",
    "        tweet_util.get_emo_class_label(predicted_classes[2])                                       \n",
    "        ))    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Past Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "sample_df = test_df.sample(10)\n",
    "columns = ['TWEET', 'LABEL']\n",
    "for tweet, label in zip(sample_df.TWEET.values, sample_df.LABEL.values):\n",
    "    # print(\"label: {}, tweet: {}\".format(label, tweet))\n",
    "    \n",
    "    reviews = [tweet]\n",
    "\n",
    "    predicted_classes = predictor.predict(reviews)\n",
    "    print(predicted_classes)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction, Ground_truth- 1:ğŸ’•, 9:ğŸ¤” \n",
      " tweet: why am i still up\n",
      "Prediction, Ground_truth- 1:ğŸ’•, 4:ğŸ˜Š \n",
      " tweet:  gud eve frm here fe al\n",
      "Prediction, Ground_truth- 1:ğŸ’•, 2:ğŸ”¥ \n",
      " tweet:  he throws 95 105 mph for those wondering \n",
      "Prediction, Ground_truth- 1:ğŸ’•, 7:ğŸ˜­ \n",
      " tweet: power just pissed me off\n",
      "Prediction, Ground_truth- 1:ğŸ’•, 6:ğŸ˜© \n",
      " tweet: feels like i'm getting sick\n",
      "Prediction, Ground_truth- 1:ğŸ’•, 1:ğŸ’• \n",
      " tweet: always been the baddest\n",
      "Prediction, Ground_truth- 1:ğŸ’•, 7:ğŸ˜­ \n",
      " tweet:  oh my god\n",
      "Prediction, Ground_truth- 0:â¤, 0:â¤ \n",
      " tweet:  still following people all day send me a screenshot that you got the song \n",
      "Prediction, Ground_truth- 1:ğŸ’•, 6:ğŸ˜© \n",
      " tweet: to early for college\n",
      "Prediction, Ground_truth- 1:ğŸ’•, 6:ğŸ˜© \n",
      " tweet: beh tambak ang assignments\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "sample_df = test_df.sample(10)\n",
    "columns = ['TWEET', 'LABEL']\n",
    "for tweet, label in zip(sample_df.TWEET.values, sample_df.LABEL.values):\n",
    "    # print(\"label: {}, tweet: {}\".format(label, tweet))\n",
    "    \n",
    "    reviews = [tweet]\n",
    "\n",
    "    predicted_classes = predictor.predict(reviews)[0]\n",
    "    print('Prediction, Ground_truth- {}:{}, {}:{} \\n tweet: {}'.format(\n",
    "        predicted_classes, \n",
    "        tweet_util.get_emo_class_label(predicted_classes),\n",
    "        label, \n",
    "        tweet_util.get_emo_class_label(label),        \n",
    "        tweet))    \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
