{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 6.1] Train a Model using SageMaker Component in Kubeflow\n",
    "\n",
    "<font color=\"red\">**만일 이 노트북을 실행하기 전에 [관련 가이드](install_EKS_Kubeflow/README.md) 안보셨다면, 먼저 보시고 가이드를 따라 가세요.**</font>\n",
    "\n",
    "이 노트북은 Kubeflow 노트북 서버에서 실행이 됩니다. 아래와 같은 작업을 실행 합니다.\n",
    "\n",
    "- 필요한 Package를 설치 합니다. (AWS boto3, Kubeflow Pipeline SDK)\n",
    "- SageMaker Components를 가져옵니다.\n",
    "- S3의 입력 데이타를 설정 합니다.\n",
    "- Kubeflow Pipeline을 정의 합니다.\n",
    "- Kubeflow Experiment를 실행 합니다.\n",
    "\n",
    "**아래 일부 코드는 하드코드가 있습니다. (예: S3 데이타 경로, Region 이름). 이는 EKS/Kubeflow 설치환경 및 데이타 장소에 종속적입니다.실제 환경 구성후에 실행시 변경 해야 합니다.**\n",
    "\n",
    "---\n",
    "이 노트북의 실행 시간은 **약 15분** 걸립니다. <br>\n",
    "2개의 ml.p3.2xlarge instance type으로 학습시에 약 15분 소요 됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 이 노트북이 Kubeflow 노트북에서 실행이 되어 완료 하면 Kubeflow Dashboard에 나오는 화면 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kubeflowPipeline](img/kubeflow-pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 Kubeflow pipeline에서 SageMaker training job 이 실행되고 있는 화면 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kubeflow-training](img/kubeflow-training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 Kubeflow pipeline에서 SageMaker creating model job 이 실행되고 있는 화면 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kubeflow-creating-model](img/kubeflow-creating-model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 SageMaker Console에 가서 training job 이 실행된 것을 확인 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kubeflow-sagemaker-train-job](img/kubeflow-sagemaker-train-job.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS boto3 package 설치\n",
    "\n",
    "**아래 pip install boto3 가 에러시 커널을 리스트하고 해주세요**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install boto3 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Kubeflow Pipelines SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://storage.googleapis.com/ml-pipeline/release/0.1.29/kfp.tar.gz --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resion이 ap-northeast-2 가 아니면 해당 Region으로 변경 해주세요**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "#################################\n",
    "#################################\n",
    "# REPLACE AWS_REGION= with the current region\n",
    "#  surround with single quotes\n",
    "AWS_REGION='ap-northeast-2'\n",
    "\n",
    "AWS_ACCOUNT_ID=boto3.client('sts').get_caller_identity().get('Account')\n",
    "print('Account ID: {}'.format(AWS_ACCOUNT_ID))\n",
    "\n",
    "S3_BUCKET='sagemaker-{}-{}'.format(AWS_REGION, AWS_ACCOUNT_ID)\n",
    "print('S3 Bucket: {}'.format(S3_BUCKET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run the following command to load Kubeflow Pipelines SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import components\n",
    "from kfp import dsl\n",
    "from kfp.aws import use_aws_secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Load reusable sagemaker components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래는 과거 버전의 sagemaker_train_op 임\n",
    "# sagemaker_train_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0ad6c28d32e2e790e6a129b7eb1de8ec59c1d45f/components/aws/sagemaker/train/component.yaml')\n",
    "sagemaker_train_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/cb36f87b727df0578f4c1e3fe9c24a30bb59e5a2/components/aws/sagemaker/train/component.yaml')\n",
    "sagemaker_model_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0ad6c28d32e2e790e6a129b7eb1de8ec59c1d45f/components/aws/sagemaker/model/component.yaml')\n",
    "sagemaker_deploy_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/0ad6c28d32e2e790e6a129b7eb1de8ec59c1d45f/components/aws/sagemaker/deploy/component.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**아래의 S3 train, validation, test 의 경로는 하드코딩이 되어 있습니다.** <br>\n",
    "SageMaker Notebook으로 되돌아 가셔서 <br>\n",
    "<font color=\"red\">\"1.1.Prepare-Tweet-Data.ipynb, 2.1.Convert-Input-TFRecord.ipynb\" 노트묵을 실행하고 아래의 변수들의 값을 프린트하여 그 값을 아래의 변수에 할당 하세요</font>\n",
    "```\n",
    "print(processed_train_data_s3_uri)\n",
    "print(processed_validation_data_s3_uri)\n",
    "print(processed_test_data_s3_uri)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 입력 데이타 정의\n",
    "**[중요] 아래의 각 경로를 수정 해야합니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train = \"<print(processed_train_data_s3_uri)>\"\n",
    "print(\"s3_train: \\n\", s3_train)\n",
    "\n",
    "\n",
    "s3_validation = \"print(processed_validation_data_s3_uri)>\"\n",
    "print(\"s3_validation: \\n\", s3_validation)\n",
    "\n",
    "\n",
    "s3_test = \"<print(processed_test_data_s3_uri)>\"\n",
    "print(\"s3_test: \\n\", s3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이 입력 채널을 정의 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels='[ \\\n",
    "                    { \\\n",
    "                        \"ChannelName\": \"train\", \\\n",
    "                        \"DataSource\": { \\\n",
    "                            \"S3DataSource\": { \\\n",
    "                                \"S3DataType\": \"S3Prefix\", \\\n",
    "                                \"S3Uri\": \"'+s3_train+'\", \\\n",
    "                                \"S3DataDistributionType\": \"ShardedByS3Key\" \\\n",
    "                            } \\\n",
    "                        }, \\\n",
    "                        \"CompressionType\": \"None\", \\\n",
    "                        \"RecordWrapperType\": \"None\" \\\n",
    "                    }, \\\n",
    "                    { \\\n",
    "                        \"ChannelName\": \"validation\", \\\n",
    "                        \"DataSource\": { \\\n",
    "                            \"S3DataSource\": { \\\n",
    "                                \"S3DataType\": \"S3Prefix\", \\\n",
    "                                \"S3Uri\": \"'+s3_validation+'\", \\\n",
    "                                \"S3DataDistributionType\": \"ShardedByS3Key\" \\\n",
    "                            } \\\n",
    "                        }, \\\n",
    "                        \"CompressionType\": \"None\", \\\n",
    "                        \"RecordWrapperType\": \"None\" \\\n",
    "                    }, \\\n",
    "                    { \\\n",
    "                        \"ChannelName\": \"test\", \\\n",
    "                        \"DataSource\": { \\\n",
    "                            \"S3DataSource\": { \\\n",
    "                                \"S3DataType\": \"S3Prefix\", \\\n",
    "                                \"S3Uri\": \"'+s3_test+'\", \\\n",
    "                                \"S3DataDistributionType\": \"ShardedByS3Key\" \\\n",
    "                            } \\\n",
    "                        }, \\\n",
    "                        \"CompressionType\": \"None\", \\\n",
    "                        \"RecordWrapperType\": \"None\" \\\n",
    "                    } \\\n",
    "                ]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs= \"2\"\n",
    "train_steps_per_epoch= \"10\"\n",
    "\n",
    "max_seq_length = \"32\"\n",
    "learning_rate= \"1e-5\"\n",
    "epsilon= \"0.00000001\"\n",
    "train_batch_size= \"128\"\n",
    "validation_batch_size= \"128\"\n",
    "test_batch_size= \"128\"\n",
    "\n",
    "validation_steps= \"100\"\n",
    "test_steps= \"100\"\n",
    "\n",
    "train_instance_count= \"2\" \n",
    "train_instance_type='ml.p3.2xlarge'\n",
    "train_volume_size= \"1024\"\n",
    "\n",
    "use_xla= \"True\"\n",
    "use_amp= \"True\"\n",
    "freeze_bert_layer= \"True\"\n",
    "enable_checkpointing= \"True\"\n",
    "input_mode='Pipe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Create Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**SageMaker의 Train 을 실행할 Role 을 적어주세요.**</font>\n",
    "각자 구성한 역할의 ARN을 넣으셔야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAGEMAKER_ROLE_ARN = 'arn:aws:iam::343441690612:role/service-role/AmazonSageMaker-ExecutionRole-20200801T163342'\n",
    "SAGEMAKER_ROLE_ARN = \"<>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"4.2.1.Make-Custom-Inference-Image-ECR.ipynb\" 에서 생성하여 ECR에 등록한 Image의 ARN을 아래에 넣어 주세요\n",
    "\n",
    "<font color=\"red\">아래를 각자의 환경에 맞게 수정하셔야 합니다.</font>\n",
    "\n",
    "아래 예시 처럼 ECR 에 가셔서 본인의 이미지 확인 하세요.\n",
    "\n",
    "![ECRImages.png](img/ECRImages.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS_ECR_TRAIN_REGISTRY = \"343441690612.dkr.ecr.ap-northeast-2.amazonaws.com/bert2tweet:latest\"\n",
    "AWS_ECR_TRAIN_REGISTRY = \"<>\"\n",
    "\n",
    "# Inference Image로 아래 image를 사용하여 SageMaker Model Object 생성    \n",
    "# TF_INFER_IMAGE = '520713654638.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-tensorflow-serving:1.14.0-gpu'\n",
    "TF_INFER_IMAGE = '<>'\n",
    "\n",
    "model_output_prefix = 'sagemaker-scikit-learn-2020-08-02-01-14-52-546/model'\n",
    "model_output_path = 's3://{}/{}'.format(S3_BUCKET,model_output_prefix )\n",
    "# model_output_path = 's3://sagemaker-us-west-2-057716757052/sagemaker-scikit-learn-2020-06-28-05-08-39-660/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='Tweet BERT Classification pipeline',\n",
    "    description='Tweet BERT Classification using KMEANS in SageMaker'\n",
    ")\n",
    "def tweet_BERT(\n",
    "    region = AWS_REGION,\n",
    "    image = AWS_ECR_TRAIN_REGISTRY,\n",
    "    dataset_path = channels,\n",
    "    instance_type = 'ml.p3.8xlarge',\n",
    "    instance_count = 2,\n",
    "    volume_size = '50',\n",
    "    model_putput_path = model_output_path,\n",
    "    role_arn = SAGEMAKER_ROLE_ARN,\n",
    "    network_isolation='False',\n",
    "    traffic_encryption='False',\n",
    "    spot_instance='False'    \n",
    "    ):\n",
    "    # Component 1\n",
    "    training = sagemaker_train_op(\n",
    "        region = region,\n",
    "        image = image,\n",
    "        channels=channels,        \n",
    "        instance_type = instance_type,\n",
    "        instance_count = instance_count,\n",
    "        volume_size = volume_size,\n",
    "        model_artifact_path=model_output_path,\n",
    "        role=role_arn,\n",
    "        network_isolation=network_isolation,\n",
    "        traffic_encryption=traffic_encryption,\n",
    "        spot_instance=spot_instance,        \n",
    "        hyperparameters={'epochs': epochs,\n",
    "                        'learning_rate': learning_rate,\n",
    "                        'epsilon': epsilon,\n",
    "                        'train_batch_size': train_batch_size,\n",
    "                        'validation_batch_size': validation_batch_size,\n",
    "                        'test_batch_size': test_batch_size,                                             \n",
    "                        'train_steps_per_epoch': train_steps_per_epoch,\n",
    "                        'validation_steps': validation_steps,\n",
    "                        'test_steps': test_steps,\n",
    "                        'use_xla': use_xla,\n",
    "                        'use_amp': use_amp,                                             \n",
    "                        'max_seq_length': max_seq_length,\n",
    "                        'freeze_bert_layer': freeze_bert_layer,\n",
    "                        'enable_checkpointing': enable_checkpointing\n",
    "                        },        \n",
    "    ).apply(use_aws_secret('aws-secret', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY'))        \n",
    "    # Component 2\n",
    "    create_model = sagemaker_model_op(\n",
    "        region = region,\n",
    "        image = TF_INFER_IMAGE,\n",
    "        model_artifact_url = training.outputs['model_artifact_url'],\n",
    "        model_name = training.outputs['job_name'],\n",
    "        role = role_arn\n",
    "    ).apply(use_aws_secret('aws-secret', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY'))\n",
    "    \n",
    "#     # Component 3\n",
    "#     prediction = sagemaker_deploy_op(\n",
    "#         region=region,\n",
    "#         model_name=create_model.output\n",
    "#     ).apply(use_aws_secret('aws-secret', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile 하여 tweet_BERT 함수를 tweet_BERT.zip 으로 만듦니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(tweet_BERT, 'tweet_BERT.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 압축을 해제하면 아래와 같은 pipeline 정의를 가지고 있는 yaml 파일이 생성 됩니다.\n",
    "```\n",
    "Archive:  ./tweet_BERT.zip\n",
    "  inflating: pipeline.yaml \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -o ./tweet_BERT.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Create Kubeflow Experiment\n",
    "\n",
    "Kubeflow Experiment를 생성하여 실행하면 SageMaker에서 pipeline.yaml 이 실행 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()\n",
    "aws_experiment = client.create_experiment(name='aws')\n",
    "\n",
    "exp_name    = f'tweet-BERT-train-deploy-kfp-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())}'\n",
    "my_run = client.run_pipeline(aws_experiment.id, exp_name, 'tweet_BERT.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
